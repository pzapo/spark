{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkConf\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, VectorIndexer, StringIndexer\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder, TrainValidationSplit\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "# Algorithms\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "# Others\n",
    "from collections import OrderedDict\n",
    "\n",
    "# Graphs libs\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.simplefilter(action='ignore', category=UserWarning)\n",
    "\n",
    "# Spark context simple configuration\n",
    "spark = SparkSession.builder.config(conf=SparkConf()).getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Helpers.technical_indicators import calc_ti\n",
    "from Helpers.generated_features import features_from_OHLC\n",
    "from Helpers.CustomTS import TrainValidationSplitSorted\n",
    "from Helpers.best_model_params import *\n",
    "\n",
    "from ProcessingData.processing import initial_processing, calc_profit, transform_date, train_test_split, complete_processing\n",
    "from Stats.measures import calc_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "ManualSplit = True\n",
    "SORT = True\n",
    "CHUNKS = 10\n",
    "\n",
    "CV = False\n",
    "\n",
    "DEBUG = False\n",
    "RANDOM_SEED = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# path_to_csv = \"s3://stocksets100/Orlen.csv\"\n",
    "path = \"./Datasets/KGHA.csv\"\n",
    "df = complete_processing(spark, path)\n",
    "\n",
    "train, test = train_test_split(spark, df, CHUNKS, SORT, ManualSplit, RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Index labels, adding metadata to the label column.\n",
    "# Fit on whole dataset to include all labels in index.\n",
    "featuresCols = df.columns\n",
    "featuresCols.remove('Profit')\n",
    "featuresCols.remove('id')\n",
    "\n",
    "print(featuresCols)\n",
    "\n",
    "# Vector Assembler\n",
    "# This concatenates all feature columns into a single feature vector in a new column \"rawFeatures\".\n",
    "# Used for assembling features into a vector.\n",
    "# We will pass all the columns that we are going to use for the prediction to the VectorAssembler and\n",
    "# it will create a new vector column.\n",
    "vectorAssembler_rt = VectorAssembler(\n",
    "    inputCols=featuresCols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Patrameters grid testing\n",
    "# rt = DecisionTreeClassifier(\n",
    "#     labelCol='Profit', featuresCol=\"features\", minInfoGain=0.01,  maxBins=200)\n",
    "\n",
    "rt = RandomForestClassifier(\n",
    "    labelCol='Profit', featuresCol=\"features\", numTrees=10, maxBins=300)\n",
    "\n",
    "max_Depth_Range = [3]\n",
    "min_InstancesPerNode = list(range(5, 15))\n",
    "\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rt.maxDepth, max_Depth_Range) \\\n",
    "    .addGrid(rt.maxMemoryInMB, [1000] ).build()\n",
    "\n",
    "# We define an evaluation metric. This tells Validator how well we are doing by comparing the true\n",
    "# labels with predictions.\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=rt.getLabelCol(),\n",
    "    metricName='accuracy',\n",
    "    predictionCol=rt.getPredictionCol())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Declare the CrossValidator, which runs model tuning for us.\n",
    "if CV:\n",
    "    val = CrossValidator(\n",
    "        estimator=rt,\n",
    "        evaluator=multi,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        numFolds=2)\n",
    "else:\n",
    "    val = TrainValidationSplitSorted(\n",
    "        chunks = CHUNKS,\n",
    "        spark = spark,\n",
    "        estimator=rt,\n",
    "        estimatorParamMaps=paramGrid,\n",
    "        evaluator=evaluator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Creating Final pipeline object\n",
    "pipeline_rt = Pipeline(stages=[vectorAssembler_rt, val])\n",
    "\n",
    "# FITTING!\n",
    "pipelineModel_rt = pipeline_rt.fit(train)\n",
    "\n",
    "# Getting the Best Model\n",
    "best_classifier = pipelineModel_rt.stages[-1].bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "# print('Features importances' + str(best_classifier.featureImportances))\n",
    "final_features = best_classifier.featureImportances\n",
    "\n",
    "feature_dict = {}\n",
    "for feature, importance in zip(featuresCols, final_features):\n",
    "    feature_dict[feature] = importance\n",
    "\n",
    "feature_dict = OrderedDict(sorted(feature_dict.items(), key=lambda t: t[1], reverse=True)) \n",
    "\n",
    "i = 1\n",
    "for feature, importance in feature_dict.items():\n",
    "    print(\"{} ; {} ; {}\".format(i, feature, round(importance, 3)))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "# Making Predictions!\n",
    "predictions = pipelineModel_rt.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "#evaluate results\n",
    "calc_metrics(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": [
    "if DEBUG != True:\n",
    "    df_to_plot_rt = predictions.select('prediction', 'Profit')\n",
    "    df_to_plot_rt = df_to_plot_rt.toPandas()\n",
    "    plt.figure(figsize=(24, 3))\n",
    "    plt.plot(df_to_plot_rt)\n",
    "    plt.legend(df_to_plot_rt.columns)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 909 training examples and 398 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 163.,   47.],\n",
      "             [ 110.,   78.]])\n",
      "Accuracy = 0.6055\n",
      "Recall = 0.6055\n",
      "F1 Score = 0.6055\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 904 training examples and 403 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 174.,   43.],\n",
      "             [ 109.,   77.]])\n",
      "Accuracy = 0.6228\n",
      "Recall = 0.6228\n",
      "F1 Score = 0.6228\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 905 training examples and 402 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 170.,   48.],\n",
      "             [ 100.,   84.]])\n",
      "Accuracy = 0.6318\n",
      "Recall = 0.6318\n",
      "F1 Score = 0.6318\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 907 training examples and 400 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 161.,   41.],\n",
      "             [ 106.,   92.]])\n",
      "Accuracy = 0.6325\n",
      "Recall = 0.6325\n",
      "F1 Score = 0.6325\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 900 training examples and 407 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 180.,   49.],\n",
      "             [  83.,   95.]])\n",
      "Accuracy = 0.6757\n",
      "Recall = 0.6757\n",
      "F1 Score = 0.6757\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 908 training examples and 399 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 156.,   47.],\n",
      "             [ 108.,   88.]])\n",
      "Accuracy = 0.6115\n",
      "Recall = 0.6115\n",
      "F1 Score = 0.6115\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 902 training examples and 405 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 184.,   36.],\n",
      "             [  97.,   88.]])\n",
      "Accuracy = 0.6716\n",
      "Recall = 0.6716\n",
      "F1 Score = 0.6716\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 904 training examples and 403 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 197.,   32.],\n",
      "             [  89.,   85.]])\n",
      "Accuracy = 0.6998\n",
      "Recall = 0.6998\n",
      "F1 Score = 0.6998\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 901 training examples and 406 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 195.,   47.],\n",
      "             [  98.,   66.]])\n",
      "Accuracy = 0.6429\n",
      "Recall = 0.6429\n",
      "F1 Score = 0.6429\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 903 training examples and 404 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 165.,   47.],\n",
      "             [ 112.,   80.]])\n",
      "Accuracy = 0.6064\n",
      "Recall = 0.6064\n",
      "F1 Score = 0.6064\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 900 training examples and 407 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 173.,   43.],\n",
      "             [ 102.,   89.]])\n",
      "Accuracy = 0.6437\n",
      "Recall = 0.6437\n",
      "F1 Score = 0.6437\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 901 training examples and 406 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 193.,   35.],\n",
      "             [ 103.,   75.]])\n",
      "Accuracy = 0.6601\n",
      "Recall = 0.6601\n",
      "F1 Score = 0.6601\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 894 training examples and 413 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 175.,   44.],\n",
      "             [ 115.,   79.]])\n",
      "Accuracy = 0.6150\n",
      "Recall = 0.6150\n",
      "F1 Score = 0.6150\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 903 training examples and 404 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 170.,   47.],\n",
      "             [ 101.,   86.]])\n",
      "Accuracy = 0.6337\n",
      "Recall = 0.6337\n",
      "F1 Score = 0.6337\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 901 training examples and 406 test examples.\n",
      "Summary Stats\n",
      "DenseMatrix([[ 178.,   32.],\n",
      "             [ 121.,   75.]])\n",
      "Accuracy = 0.6232\n",
      "Recall = 0.6232\n",
      "F1 Score = 0.6232\n",
      "\n",
      "\n",
      "#########################################################################\n",
      "We have 903 training examples and 404 test examples.\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# path_to_csv = \"s3://stocksets100/Orlen.csv\"\n",
    "path = \"./Datasets/KGHA.csv\"\n",
    "df = complete_processing(spark, path)\n",
    "ManualSplit = False\n",
    "for i in range(30):\n",
    "    train, test = train_test_split(spark, df, CHUNKS, SORT, ManualSplit, RANDOM_SEED + i)\n",
    "    predictions = pipelineModel_rt.transform(test)\n",
    "    calc_metrics(predictions)\n",
    "    i+=1\n",
    "    print(\"#########################################################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hideCode": false,
    "hidePrompt": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Hide code",
  "hide_code_all_hidden": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
